{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04f47f8a",
   "metadata": {},
   "source": [
    "# An example of train pipeline, model and lossfn design\n",
    "\n",
    "Since we need to detect people in realtime, we decided to search for groundbreaking papers in that area. One of them [YOLOv1](https://arxiv.org/pdf/1506.02640), that for 2015 year was one of the fastest CNN models for real time detection. Thus, we decided to learn its design and recreate approaches to achieve same or even better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "038aa900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, sys, platform\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f26d64e",
   "metadata": {},
   "source": [
    "## **Important note**\n",
    "\n",
    "This .ipynb is just a structural reference, that may not working or training too long, miss some preparational parts. This will be updated in nearest future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52db958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(input,output,kernel,stride=1,padding=None):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(input,output,kernel,stride,padding if padding is not None else kernel//2,bias=False),\n",
    "            nn.BatchNorm2d(output),\n",
    "            nn.LeakyReLU(0.1,inplace=True)\n",
    "        )\n",
    "\n",
    "class YOLOv1(nn.Module):\n",
    "    def __init__(self, S=7, B=2, C=1):\n",
    "        super(YOLOv1, self).__init__()\n",
    "        self.S = S  # Grid size\n",
    "        self.B = B  # Number of bounding boxes per grid cell\n",
    "        self.C = C  # Number of classes, we will use 1 for person detection\n",
    "\n",
    "        L =[]\n",
    "        L+=[layer(3,64,7,2,3),  nn.MaxPool2d(2,2)]\n",
    "        L+=[layer(64,192,3),    nn.MaxPool2d(2,2)]\n",
    "        L+=[layer(192,128,1),   layer(128,256,3),       layer(256,256,1), layer(256,512,3),  nn.MaxPool2d(2,2)]\n",
    "        L+=[layer(512,256,1),   layer(256,512,3)]*4 + [ layer(512,512,1), layer(512,1024,3), nn.MaxPool2d(2,2)]\n",
    "        L+=[layer(1024,512,1),  layer(512,1024,3)]*2 \n",
    "        L+=[layer(1024,1024,3), layer(1024,1024,3,2,1)]\n",
    "        L+=[layer(1024,1024,3), layer(1024,1024,3)]\n",
    "        self.backbone = nn.Sequential(*L)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024 * S * S, 4096),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, S * S * (C + B * 5))\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(x)\n",
    "        # [batch_size, S*S*(C+5*B)] -> [batch_size, S, S, C+5*B]\n",
    "        # [C+5*B] = [x,y,w,h,conf1,conf2,...,confB,class1,class2,...,classC]\n",
    "        x = x.view(-1, self.S, self.S, self.C + self.B * 5)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28ad740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _iou_xywh(a, b, eps=1e-9):\n",
    "    # a,b: [...,4] in cx,cy,w,h (abs in [0,1])\n",
    "    a_x1 = a[...,0] - a[...,2]/2; a_y1 = a[...,1] - a[...,3]/2\n",
    "    a_x2 = a[...,0] + a[...,2]/2; a_y2 = a[...,1] + a[...,3]/2\n",
    "    b_x1 = b[...,0] - b[...,2]/2; b_y1 = b[...,1] - b[...,3]/2\n",
    "    b_x2 = b[...,0] + b[...,2]/2; b_y2 = b[...,1] + b[...,3]/2\n",
    "    inter = (torch.minimum(a_x2,b_x2)-torch.maximum(a_x1,b_x1)).clamp_(min=0) * \\\n",
    "            (torch.minimum(a_y2,b_y2)-torch.maximum(a_y1,b_y1)).clamp_(min=0)\n",
    "    area_a = (a_x2-a_x1).clamp(min=0)*(a_y2-a_y1).clamp(min=0)\n",
    "    area_b = (b_x2-b_x1).clamp(min=0)*(b_y2-b_y1).clamp(min=0)\n",
    "    return inter / (area_a + area_b - inter + eps)\n",
    "\n",
    "class YoloV1Loss(nn.Module):\n",
    "    def __init__(self, S=7, B=2, lambda_coord=5.0, lambda_noobj=0.5):\n",
    "        super().__init__()\n",
    "        self.S, self.B = S, B\n",
    "        self.lc = lambda_coord\n",
    "        self.lno = lambda_noobj\n",
    "        self.mse = nn.MSELoss(reduction='sum')\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        \"\"\"\n",
    "        pred: [N,S,S,B*5+1] raw logits\n",
    "        target: {'tconf':[N,S,S,1], 'txywh':[N,S,S,4], 'tcls':[N,S,S,1]}\n",
    "        \"\"\"\n",
    "        N, S, B = pred.size(0), self.S, self.B\n",
    "        device = pred.device\n",
    "\n",
    "        # split prediction\n",
    "        pb = pred[...,:B*5].view(N,S,S,B,5)         # x,y,w,h,conf (raw)\n",
    "        pcls = pred[...,B*5:]                       # one class logit\n",
    "\n",
    "        # activations per YOLOv1 practice\n",
    "        px = pb[...,0].sigmoid(); py = pb[...,1].sigmoid()\n",
    "        pw = pb[...,2].relu().pow(2)                # ensure positive; model learns sqrt(w)\n",
    "        ph = pb[...,3].relu().pow(2)\n",
    "        pc = pb[...,4].sigmoid()\n",
    "        pcl = pcls.sigmoid()                        # single-class prob\n",
    "\n",
    "        # absolute boxes in [0,1]\n",
    "        gy, gx = torch.meshgrid(torch.arange(S, device=device),\n",
    "                                torch.arange(S, device=device), indexing='ij')\n",
    "        gx = gx.view(1,S,S,1).float(); gy = gy.view(1,S,S,1).float()\n",
    "        bx = (gx + px)/S; by = (gy + py)/S\n",
    "        bw = pw/S; bh = ph/S\n",
    "        boxes_abs = torch.stack([bx,by,bw,bh], dim=-1)  # [N,S,S,B,4]\n",
    "\n",
    "        # targets\n",
    "        tconf = target['tconf'].to(device)          # [N,S,S,1]\n",
    "        txywh = target['txywh'].to(device)          # [N,S,S,4]\n",
    "        tcls  = target['tcls' ].to(device)          # [N,S,S,1]\n",
    "\n",
    "        # assign responsible box by IoU\n",
    "        ious = _iou_xywh(boxes_abs, txywh.unsqueeze(3).expand_as(boxes_abs))  # [N,S,S,B]\n",
    "        iou_max, argmax = ious.max(dim=3, keepdim=True)                       # [N,S,S,1]\n",
    "        obj_mask   = tconf                                                     # [N,S,S,1]\n",
    "        noobj_mask = 1.0 - obj_mask\n",
    "\n",
    "        # one-hot over B for responsible box\n",
    "        resp = torch.zeros_like(ious)\n",
    "        resp.scatter_(3, argmax, 1.0)              # [N,S,S,B]\n",
    "        resp = resp * obj_mask                     # mask only cells with object\n",
    "\n",
    "        # ----- coordinate loss (only responsible box) -----\n",
    "        # predicted responsible components\n",
    "        pxr = (px * resp).sum(dim=3, keepdim=True)\n",
    "        pyr = (py * resp).sum(dim=3, keepdim=True)\n",
    "        pwr = (pw * resp).sum(dim=3, keepdim=True).clamp(min=1e-9)\n",
    "        phr = (ph * resp).sum(dim=3, keepdim=True).clamp(min=1e-9)\n",
    "\n",
    "        # targets to cell-relative and sqrt(w,h) (YOLOv1)\n",
    "        tx, ty, tw, th = txywh.unbind(-1)\n",
    "        tx = tx * S - gx; ty = ty * S - gy\n",
    "        tw = (tw * S).clamp(min=1e-9).sqrt()\n",
    "        th = (th * S).clamp(min=1e-9).sqrt()\n",
    "\n",
    "        coord_loss = self.lc * (\n",
    "            ((pxr - tx.unsqueeze(-1))**2 + (pyr - ty.unsqueeze(-1))**2 +\n",
    "             (pwr.sqrt() - tw.unsqueeze(-1))**2 + (phr.sqrt() - th.unsqueeze(-1))**2) * obj_mask\n",
    "        ).sum()\n",
    "\n",
    "        # ----- confidence loss -----\n",
    "        # target conf for responsible box = IoU; for others and empty = 0\n",
    "        conf_tgt_resp = (ious * resp).detach()          # [N,S,S,B]\n",
    "        conf_obj_loss   = ((pc - conf_tgt_resp)**2 * resp).sum()\n",
    "        conf_noobj_loss = self.lno * ((pc**2) * (1.0 - resp)).sum()\n",
    "        conf_loss = conf_obj_loss + conf_noobj_loss\n",
    "\n",
    "        # ----- class loss (single class) -----\n",
    "        cls_loss = ((pcl - tcls)**2 * obj_mask).sum()\n",
    "\n",
    "        total = (coord_loss + conf_loss + cls_loss) / N\n",
    "        logs = {\n",
    "            'loss': total.item(),\n",
    "            'L_coord': coord_loss.item()/N,\n",
    "            'L_conf_obj': conf_obj_loss.item()/N,\n",
    "            'L_conf_noobj': conf_noobj_loss.item()/N,\n",
    "            'L_cls': cls_loss.item()/N\n",
    "        }\n",
    "        return total, logs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29d5c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 7, 10])\n"
     ]
    }
   ],
   "source": [
    "model = YOLOv1(S=7, B=2, C=1)\n",
    "# [batch,3,448,448] -> [batch,7,7,C+5*B]\n",
    "x = torch.randn(1,3,448,448)\n",
    "y = model(x)  # [batch_size,7,7,11]\n",
    "print(y.shape)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=0.001\n",
    "    )\n",
    "\n",
    "\n",
    "loss_fn = YoloV1Loss(S=7,B=2,lambda_coord=5.0,lambda_noobj=0.5)\n",
    "pred = model(x)  # [N,7,7,11]\n",
    "target_batch = {\n",
    "    'tconf': torch.randn(1,7,7,1), # confidence\n",
    "    'txywh': torch.randn(1,7,7,4),  # [cx,cy,w,h]\n",
    "    'tcls': torch.randn(1,7,7,1)   # class\n",
    "}\n",
    "loss, logs = loss_fn(pred, target_batch)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
